# What AI Will Not Do
**Clear Boundaries for AI Assistance in RGDS**

This document defines **explicit limitations** on the use of AI in decisions governed by **RGDS (Regulated Gate Decision Support)**.

It is written for executives, program leaders, quality reviewers, and stakeholders who require clarity on **where AI stops** in regulated decision environments.

---

## Core Principle

AI may assist analysis.  
AI does **not** make decisions.

All decisions governed by RGDS remain **human-owned, human-approved, and human-accountable**.

---

## AI Will Not Make Decisions

AI will not:

- decide, approve, defer, or reject gate outcomes
- replace human judgment at any decision point
- determine risk posture or residual risk acceptance
- act as a decision-maker in any capacity

Decision authority always rests with named human owners.

---

## AI Will Not Act Autonomously

AI will not:

- initiate actions or workflows
- operate without explicit human invocation
- function as an agent or autonomous system
- execute tasks without human review and disposition

There is no permitted path for autonomous or agentic behavior.

---

## AI Will Not Override or Silence Humans

AI will not:

- override human reviewers or approvers
- suppress dissenting opinions or alternatives
- resolve disagreements between stakeholders
- substitute for governance or escalation processes

Disagreement and abstention remain valid human outcomes.

---

## AI Will Not Become Evidence of Record

AI outputs:

- are not evidence of record by default
- do not replace source documents or primary data
- cannot satisfy regulatory or quality requirements on their own

AI outputs may support analysis, but must always be evaluated against authoritative sources.

---

## AI Will Not Operate Without Disclosure

AI will not:

- influence decisions without explicit disclosure
- introduce hidden assumptions or rationale
- operate in a manner that cannot be inspected or explained

All AI assistance must be **visible, attributable, and reviewable**.

---

## AI Will Not Create Dependency

Decisions governed under RGDS must remain defensible **if all AI outputs are removed**.

AI may accelerate analysis, but must never become a prerequisite for decision legitimacy.

---

## Why These Limits Exist

In regulated environments, the primary risk is not incorrect analysis.

The primary risk is **unclear accountability**.

These boundaries ensure that:
- ownership remains explicit
- governance remains auditable
- decisions remain defensible at the time they are made

---

## Status

This document is a **governance clarification**, not a technical specification.

It defines what AI will **not** do in RGDS-governed decisions.
